#!/usr/bin/env python3

# Convert the pickled format generated by prepare_data_for_gpt.py into
# the indexed format consumed e.g. by Megatron.

import sys

import torch

from argparse import ArgumentParser

from pickled import PickledDataset
from megatron.data import indexed_dataset


def argparser():
    ap = ArgumentParser()
    ap.add_argument(
        '--key',
        default='input_ids',
        help='key for data in pickle'
    )
    ap.add_argument(
        '--vocab-size',
        type=int,
        required=True,
        help='vocabulary size'
    )
    ap.add_argument(
        '--output-prefix',
        required=True,
        help='output file path'
    )
    ap.add_argument(
        '--dataset-impl',
        default='mmap',
        choices=['lazy', 'cached', 'mmap']
    )
    ap.add_argument('pickle', nargs='+')
    return ap


def main(argv):
    args = argparser().parse_args(argv[1:])

    output_bin_fn = f'{args.output_prefix}.bin'
    output_idx_fn = f'{args.output_prefix}.idx'

    builder = indexed_dataset.make_builder(
        output_bin_fn,
        impl=args.dataset_impl,
        vocab_size=args.vocab_size
    )

    for fn in args.pickle:
        for example in PickledDataset(fn):
            ids = example[args.key]
            builder.add_item(torch.IntTensor(ids))
            builder.end_document()
    builder.finalize(output_idx_fn)


if __name__ == '__main__':
    sys.exit(main(sys.argv))
